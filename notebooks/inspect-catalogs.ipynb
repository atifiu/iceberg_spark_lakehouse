{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694fd852-8c95-411f-864c-919941ba9d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30542263-049f-49aa-9ca1-c821d5cf818e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 13:25:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17dad7b-c9ad-4c89-a695-6038170df7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 13:25:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.eventLog.enabled', 'true'),\n",
      " ('spark.app.name', 'Jupyter'),\n",
      " ('spark.history.fs.logDirectory', '/home/iceberg/spark-events'),\n",
      " ('spark.sql.catalog.spark_catalog.defaultDatabase', 'db'),\n",
      " ('spark.sql.catalog.demo.s3.endpoint', 'http://minio:9000'),\n",
      " ('spark.eventLog.dir', '/home/iceberg/spark-events'),\n",
      " ('spark.app.submitTime', '1731331516902'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.master', 'local[*]'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.driver.host', '2cd90296b120'),\n",
      " ('spark.driver.extraJavaOptions',\n",
      "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions '\n",
      "  '--add-opens=java.base/java.lang=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.io=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.net=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.nio=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.security.action=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED '\n",
      "  '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED '\n",
      "  '-Djdk.reflect.useDirectMethodHandle=false'),\n",
      " ('spark.sql.catalogImplementation', 'in-memory'),\n",
      " ('spark.sql.catalog.demo.warehouse', 's3://warehouse/wh/'),\n",
      " ('spark.sql.catalog.demo.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.app.id', 'local-1731331520528'),\n",
      " ('spark.sql.extensions',\n",
      "  'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions'),\n",
      " ('spark.app.startTime', '1731331520475'),\n",
      " ('spark.sql.catalog.demo.uri', 'http://rest:8181'),\n",
      " ('spark.sql.catalog.demo.type', 'rest'),\n",
      " ('spark.driver.port', '35669'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.executor.extraJavaOptions',\n",
      "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions '\n",
      "  '--add-opens=java.base/java.lang=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.io=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.net=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.nio=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.security.action=ALL-UNNAMED '\n",
      "  '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED '\n",
      "  '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED '\n",
      "  '-Djdk.reflect.useDirectMethodHandle=false'),\n",
      " ('spark.sql.catalog.demo', 'org.apache.iceberg.spark.SparkCatalog'),\n",
      " ('spark.sql.defaultCatalog', 'demo'),\n",
      " ('spark.submit.pyFiles', ''),\n",
      " ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2cd90296b120:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Jupyter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7b86ccfe8340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "conf = SparkConf().set(\"spark.sql.catalog.spark_catalog.defaultDatabase\", \"db\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "pprint(spark.sparkContext.getConf().getAll())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9bb08e-33fa-449b-8b61-83a84cf1e7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.catalog.Catalog at 0x7b86f4372400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddb296d-5c5c-4cd5-b07d-635d1635f172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o242.currentDatabase.\n: org.apache.iceberg.exceptions.RESTException: Error occurred while processing GET request\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:332)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:252)\n\tat org.apache.iceberg.rest.HTTPClient.get(HTTPClient.java:348)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.fetchConfig(RESTSessionCatalog.java:909)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.initialize(RESTSessionCatalog.java:195)\n\tat org.apache.iceberg.rest.RESTCatalog.initialize(RESTCatalog.java:78)\n\tat org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:255)\n\tat org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:309)\n\tat org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n\tat org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:751)\n\tat org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:53)\n\tat scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:53)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.currentCatalog(CatalogManager.scala:122)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.currentNamespace(CatalogManager.scala:93)\n\tat org.apache.spark.sql.internal.CatalogImpl.currentDatabase(CatalogImpl.scala:67)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.UnknownHostException: rest: No address associated with hostname\n\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:930)\n\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:848)\n\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)\n\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:144)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:123)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:295)\n\t... 28 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrentDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/catalog.py:179\u001b[0m, in \u001b[0;36mCatalog.currentDatabase\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrentDatabase\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Returns the current default database in this session.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    'default'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrentDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o242.currentDatabase.\n: org.apache.iceberg.exceptions.RESTException: Error occurred while processing GET request\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:332)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:252)\n\tat org.apache.iceberg.rest.HTTPClient.get(HTTPClient.java:348)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.fetchConfig(RESTSessionCatalog.java:909)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.initialize(RESTSessionCatalog.java:195)\n\tat org.apache.iceberg.rest.RESTCatalog.initialize(RESTCatalog.java:78)\n\tat org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:255)\n\tat org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:309)\n\tat org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n\tat org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:751)\n\tat org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:53)\n\tat scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:53)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.currentCatalog(CatalogManager.scala:122)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.currentNamespace(CatalogManager.scala:93)\n\tat org.apache.spark.sql.internal.CatalogImpl.currentDatabase(CatalogImpl.scala:67)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.UnknownHostException: rest: No address associated with hostname\n\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:930)\n\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:848)\n\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)\n\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:144)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:450)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:162)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:172)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:142)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:152)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)\n\tat org.apache.iceberg.shaded.org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:123)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:295)\n\t... 28 more\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a15e69-af48-4458-9212-627fdaa0c829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45998b3-985c-49f3-8e9f-1125582b8cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ee8a-da4e-4827-8ea5-f8cd04aad5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('show tables from db').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd01fa6-9f46-44e2-907f-250c062bb0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"data.db.pg_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb83a7-31f4-4267-84d9-756c72049a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31642dc0-dff1-49f3-87da-6cd662857af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7d048-d502-4b66-a982-5d39767be6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415793dc-a28f-497c-8e37-b59b4608a261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
